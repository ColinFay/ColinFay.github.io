---
title: "Playing with #rstatsnyc, Neo4J and R"
post_date: 2018-04-22
layout: single
permalink: /rstatsnyc-neo4j/
categories: r-blog-en
output: jekyllthat::jekylldown
excerpt_separator: #----#
always_allow_html: yes
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(fig.path="../assets/img/")
```

A search on Twitter, some R, and just enough Neo4J. 

#----#

> Disclaimer: of course everything here could be done in pure R. But hey, where's the fun in that?

> Disclaimer bis: this blogpost relies on {neo4r}, a package still under active development. 

## Get the tweets

```{r eval = FALSE}
library(rtweet)
ny <- search_tweets("#rstatsnyc", n = 3000)
```

Tweets collected at `Sys.time()` == "2018-04-25 12:41:49 CEST"

```{r echo = FALSE}
ny <- readRDS("/Users/colin/Seafile/documents_colin/R/minimal-mistakes/ny.RDS")
```
 
```{r}
nrow(ny)
```

I might not have everything here (as I've reached the limit of 3000 tweets), but let's dive into this anyway.

## Prepare for Neo4J 

Let's get some info: 

```{r}
range(ny$created_at)
```

Here, every tweet was sent in the same month of the same year, so we can keep only the day.

```{r, message = FALSE}
library(dplyr)
ny <- ny %>% mutate(day = lubridate::day(created_at))
```

Also, as the `status_id` column is composed of large characters of 18 numbers, let's recode this column:

```{r}
library(forcats)
ny <- ny %>% mutate(status_id = fct_anon(as_factor(status_id)), 
                    status_id = as.character(status_id))
# Be sure we still have 3000 observations
length(unique(ny$status_id))
```


### The model 

Here's a model of the graph we want to create in Neo4J, made with <http://www.apcjones.com/arrows>.

![](../assets/img/tweet_model.png)

### Connect to Neo4J

```{r}
library(neo4r)
con <- neo4j_api$new(url = "http://localhost:7474/", 
                     user = "neo4j", password = "pouetpouet")
# Is the connection working?
con$ping()
```

### Create the CSV

Let's create the CSV that will be sent to Neo4J. To do this, we need to: 

+ Select the info 
+ Write the csv in my Neo4J home
+ Send a query to Neo4J to retrieve and model these CSV

> Note: we're working on a way to natively send csv with {neo4r}, so you won't have to write in Neo4J home.

```{r}
library(readr)
# CSV of tweets 
ny %>% 
  select(status_id, day, text, source, 
         lang, favorite_count, retweet_count, 
         is_quote, is_retweet) %>%
  write_csv("~/neo4j/import/ny_tweets.csv")

# CSV of users
ny %>% 
  select(status_id, screen_name) %>%
  write_csv("~/neo4j/import/ny_users.csv")

# CSV of hashtags
ny %>% 
  select(status_id, hashtags) %>%
  tidyr::unnest() %>% 
  na.omit() %>%
  write_csv("~/neo4j/import/ny_hastags.csv")

# CSV of mentions
ny %>% 
  select(status_id, mentions_screen_name) %>%
  tidyr::unnest() %>% 
  na.omit() %>%
  write_csv("~/neo4j/import/ny_mentions.csv")

# CSV of replies
ny %>% 
  select(status_id, reply_to_status_id) %>%
  na.omit() %>%
  write_csv("~/neo4j/import/ny_replies.csv")

```

Before reading the file in Neo4J, we should add some constraints to ensure the nodes are unique. If you're not familiar with this terminology, a constraint is a property that will ensure that every label is unique: for example, here, we will have to ensure that every `status_id` is unique. 

Hence, if we try to create a node with a `status_id` that already exists, this writting process will fail (and that's the reason why we are using `MERGE` for writting the nodes with constraints).

```{r, results = "hide"}
'CREATE CONSTRAINT ON (t:Tweet) ASSERT t.name IS UNIQUE' %>%
  call_api(con)
'CREATE CONSTRAINT ON (d:Day) ASSERT d.name IS UNIQUE' %>%
  call_api(con)
'CREATE CONSTRAINT ON (u:User) ASSERT u.name IS UNIQUE' %>%
  call_api(con)
'CREATE CONSTRAINT ON (h:Hashtag) ASSERT h.name IS UNIQUE' %>%
  call_api(con)
```

> Note: the messages returned `## No data returned.` are due to the fact that we haven't retrieved anything from the DB, neither stats about the call (which could be retrieved with the `include_stats` arguments) nor data. 

Importing the csv to the DB:

+ With `include_stats = TRUE`:

```{r}
# Tweets but no day
'USING PERIODIC COMMIT 500
LOAD CSV WITH HEADERS FROM "file:///ny_tweets.csv" AS csvLine
MERGE (t:Tweet { name: csvLine.status_id, text: csvLine.text, source: csvLine.source, lang: csvLine.lang, favorite_count: toInteger(csvLine.favorite_count), retweet_count: toInteger(csvLine.retweet_count), is_quote: toBoolean(csvLine.is_quote), is_retweet: toBoolean(csvLine.is_retweet)});' %>%
  call_api(con, include_stats = TRUE)
```

+ Without: 

```{r results = "hide"}
# Days 
'USING PERIODIC COMMIT 500
LOAD CSV WITH HEADERS FROM "file:///ny_tweets.csv" AS csvLine
MERGE (d:Day {name : csvLine.day} )
WITH csvLine
MATCH (t:Tweet {name: csvLine.status_id})
MATCH (d:Day {name : csvLine.day} )
MERGE (t) -[:WAS_SENT]->(d);' %>%
  call_api(con)

# Users
'USING PERIODIC COMMIT 500
LOAD CSV WITH HEADERS FROM "file:///ny_users.csv" AS csvLine
MERGE (u:User { name: csvLine.screen_name})
WITH csvLine
MATCH (u:User { name: csvLine.screen_name})
MATCH (t:Tweet {name : csvLine.status_id})
MERGE (u) -[:SENT]-> (t);' %>%
  call_api(con)

# Hashtags
'USING PERIODIC COMMIT 500
LOAD CSV WITH HEADERS FROM "file:///ny_hastags.csv" AS csvLine
MERGE (h:Hashtag { name: csvLine.hashtags})
WITH csvLine
MATCH (t:Tweet {name : csvLine.status_id})
MATCH (h:Hashtag { name: csvLine.hashtags})
MERGE (t) -[:CONTAINS]-> (h);' %>%
  call_api(con)

# Mentions
'USING PERIODIC COMMIT 500
LOAD CSV WITH HEADERS FROM "file:///ny_mentions.csv" AS csvLine
MERGE (m:User { name: csvLine.mentions_screen_name})
WITH csvLine
MATCH (t:Tweet {name : csvLine.status_id})
MATCH (m:User { name: csvLine.mentions_screen_name})
MERGE (t) -[:MENTIONS]-> (m);' %>%
  call_api(con)

# Replies
'USING PERIODIC COMMIT 500
LOAD CSV WITH HEADERS FROM "file:///ny_replies.csv" AS csvLine
MERGE (t:Tweet { name: csvLine.reply_to_status_id})
WITH csvLine
MATCH (t:Tweet {name : csvLine.status_id})
MATCH (r:Tweet {name: csvLine.reply_to_status_id})
MERGE (t) -[:REPLIES_TO]-> (r);' %>%
  call_api(con)
```

Let's see what we've got:

```{r}
con$get_constraints()
con$get_labels()
con$get_relationships()
```

## Let's explore 

### Check check

Let's start with a check to see if we have everything: 

```{r}
# Have we got all the Days?
length(unique(ny$day))
'MATCH (d:Day) RETURN COUNT(d) AS days_count' %>%
  call_api(con)

# Do we have all the users ? 
length(unique(ny$screen_name))
'MATCH (u:User) RETURN COUNT(u) AS Users_count' %>%
  call_api(con)

# All the hashtags? 
ny %>% 
  select(status_id, hashtags) %>%
  tidyr::unnest() %>% 
  na.omit() %>%
  distinct(hashtags) %>%
  nrow()

'MATCH (h:Hashtag) RETURN COUNT(h) AS Hash_count' %>%
  call_api(con)
```

Ok, so now that we have our data ready, let's explore a little bit. 

### Who tweeted the most?

```{r}
library(purrr)
'MATCH (t:Tweet) <- [:SENT] - (u:User) 
RETURN u.name AS name, COUNT(u) AS count
ORDER BY COUNT(u) DESC
LIMIT 10' %>% 
  call_api(con) %>%
  bind_cols() %>%
  set_names(c("user", "n"))
```

You might see something surprising here: why do we have to `bind_cols`? By design, `{neo4r}` does not bind columns for you, for the simple reason that you can retrieve information that might not fit into a single tidy data.frame.
 
Let's put it straight into a dataviz: 

```{r most_tweeted, message = FALSE, fig.width=10, fig.height=6, fig.align="center"}
library(ggplot2)
'MATCH (t:Tweet) <- [:SENT] - (u:User) 
RETURN u.name AS name, COUNT(u) AS count
ORDER BY COUNT(u) DESC
LIMIT 10' %>% 
  call_api(con) %>%
  bind_cols() %>%
  set_names(c("user", "n")) %>%
  ggplot() +
  aes(reorder(user, n), n) + 
  geom_col(fill = viridis::plasma(1)) + 
  coord_flip() +
  labs(x = "user",y = "tweets") +
  theme_minimal()
```

### Daily tweets 

How many tweets by day?

```{r tweets_day, message = FALSE, fig.width=10, fig.height=6, fig.align="center"}
'MATCH (t:Tweet) - [:WAS_SENT] -> (d:Day) 
RETURN d.name AS day, COUNT(d) AS count' %>% 
  call_api(con) %>%
  bind_cols() %>%
  set_names(c("day", "n")) %>%
  mutate(day  = as.numeric(day)) %>%
  ggplot() +
  aes(day, n) + 
  geom_col(fill = viridis::cividis(1)) + 
  labs(x = "day",y = "tweets") +
  theme_minimal()
```

### What are the most used hashtags?

(excluding rstatsnyc, of course)

```{r}
'MATCH (t:Tweet) -[r:CONTAINS]->(h:Hashtag) 
WHERE NOT h.name = "rstatsnyc"
RETURN h.name as Hash, COUNT(h) AS count
ORDER BY COUNT(h) DESC
LIMIT 10' %>% 
  call_api(con) %>%
  bind_cols() %>%
  set_names(c("hashtags", "n"))
```

### How many @drob or @robinson_es tweets?

(because apparently they were [fighting](https://twitter.com/robinson_es/status/987721478853545984) :) ):

Get the number of tweets:

```{r}
'MATCH (t:Tweet) <- [:SENT] - (u:User) 
WHERE u.name = "drob" OR u.name = "robinson_es" 
RETURN COUNT(u) AS count, u.name' %>% 
  call_api(con) %>%
  bind_cols() %>%
  set_names(c("n", "user"))
```

Get the average number of retweets:

```{r}
'MATCH (t:Tweet) <- [:SENT] - (u:User) 
WHERE u.name = "drob" OR u.name = "robinson_es" 
RETURN u.name AS user, COUNT(u) AS count, AVG(t.retweet_count) as mean' %>% 
  call_api(con) %>%
  bind_cols() %>%
  set_names(c("user", "n", "mean_RT"))
```

### Create a function... 

... to get the number of tweets by a user

```{r}
get_tweet_count <- function(who){
  paste0('MATCH (t:Tweet) <- [:SENT] - (u:User {name: "', who, '"}) 
  RETURN COUNT(t) AS ', who, ";") %>% 
  call_api(con)
}
get_tweet_count("RLadiesNYC")
```

### Who are the users who...

... are mentionned in a tweet containing the hashtag #Rladies?

```{r}
'MATCH (u:User) <- [m:MENTIONS] - (t:Tweet) - [:CONTAINS]-> (:Hashtag {name : "Rladies"})
RETURN u AS Name, COUNT(u) AS n' %>% 
  call_api(con) %>%
  bind_cols() %>%
  set_names(c("user", "n")) %>%
  arrange(desc(n)) %>%
  top_n(5)
```

... were mentions in a tweet containing the hashtag #rdogs :

```{r graph, message = FALSE, message = FALSE, fig.width=12, fig.height=8, fig.align="center"}
library(ggraph)
'MATCH (u:User) <- [m:MENTIONS] - (t:Tweet) - [:CONTAINS]-> (:Hashtag {name : "rdogs"})
RETURN u, m, t' %>% 
  call_api(con, type = "graph")  %>% 
  convert_to("igraph") %>%
  ggraph() + 
  geom_edge_link()+
  geom_node_label(aes(label = name, 
                      color = group)) +
  labs(title = "#rdogs and #rstatsnyc",
       subtitle = "data from Twitter",
       caption = "@_colinfay") + 
  theme_graph() 
```

... mention @RLadiesNYC

```{r graph_mentions, message = FALSE, fig.width=12, fig.height=12, fig.align="center"}
library(ggraph)
'MATCH (u:User) - [s:SENT] -> (t:Tweet) -[m:MENTIONS]-> (r:User {name:"RLadiesNYC"}) 
RETURN u, s, m, r' %>% 
  call_api(con, type = "graph")  %>% 
  convert_to("igraph") %>%
  ggraph() + 
  geom_edge_link()+
  geom_node_label(aes(label = name, 
                      color = group)) +
  labs(title = "Mentions of RLadiesNYC",
       subtitle = "data from Twitter",
       caption = "@_colinfay") + 
  theme_graph() 
```

> [{neo4r} on GitHub](https://github.com/neo4j-rstats/neo4r)



